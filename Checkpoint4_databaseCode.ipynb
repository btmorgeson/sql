{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database System Development Plan\n",
    "GROUP 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is our plan to create and populate our database system based on the normalization plan stated in Checkpoint 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV data into a new dataframe\n",
    "\n",
    "df = pd.read_csv('salary_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the connection string to a variable, conn_url\n",
    "conn_url = 'postgresql://postgres:123@localhost/checkpoint4'\n",
    "\n",
    "# Create an engine that connects to PostgreSQL server\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Establish a connection\n",
    "connection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Database Tables Based on Normalization Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x23e957837c0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are now ready to create database tables based on the normalization plan that were developed earlier\n",
    "\n",
    "# Pass the SQL statements that create all tables\n",
    "stmt = \"\"\"\n",
    "create table employee(\n",
    "\temployee_id serial,\n",
    "\tbase_salary numeric(10,2),\n",
    "\tbonus_amount numeric(10,2),\n",
    "\tstock_value numeric(10,2),\n",
    "    totalyearlycompensation numeric(10,2),\n",
    "\ttimestamp timestamp NOT NULL,\n",
    "\tprimary key (employee_id)\n",
    ");\n",
    "\n",
    "create table company(\n",
    "\tcompany_id serial,\n",
    "\tcompany varchar(100) NOT NULL,\n",
    "\tprimary key (company_id)\n",
    ");\n",
    "\n",
    "create table location(\n",
    "\tlocation_id serial,\n",
    "\tlocation_city varchar(100),\n",
    "\tlocation_state varchar(100),\n",
    "    location_add1 varchar(100),\n",
    "    location_add2 varchar(100),\n",
    "\tprimary key (location_id)\n",
    ");\n",
    "\n",
    "create table employee_company(\n",
    "\temployee_id int,\n",
    "\tcompany_id int,\n",
    "\tlocation_id int,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(company_id) references company,\n",
    "\tforeign key(location_id) references location,\n",
    "\tprimary key (employee_id, company_id, location_id)\n",
    ");\n",
    "\n",
    "create table specialization(\n",
    "\ttag_id serial,\n",
    "\ttag varchar(200),\n",
    "\tprimary key (tag_id)\n",
    ");\n",
    "\n",
    "create table employee_specialization(\n",
    "\temployee_id int,\n",
    "\ttag_id int,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(tag_id) references specialization,\n",
    "\tprimary key(employee_id)\n",
    ");\n",
    "\n",
    "create table education(\n",
    "\teducation_id serial,\n",
    "\teducation varchar(50),\n",
    "\tprimary key(education_id)\n",
    ");\n",
    "\n",
    "create table employee_qualification(\n",
    "\temployee_id int,\n",
    "\teducation_id int,\n",
    "\tyears_at_company int NOT NULL,\n",
    "\tyears_experience int NOT NULL,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(education_id) references education,\n",
    "\tprimary key(employee_id)\n",
    ");\n",
    "\n",
    "create table gender(\n",
    "\tgender varchar(10),\n",
    "\tcheck (gender \n",
    "\t\t\tin ('Male','Female', 'Other','Unknown')),\n",
    "\tprimary key(gender));\n",
    "    \n",
    "create table race(\n",
    "\trace varchar(50) primary key);\n",
    "    \n",
    "create table employee_demographics(\n",
    "\temployee_id int primary key,\n",
    "\tgender varchar(10),\n",
    "\trace varchar(50),\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(gender) references gender,\n",
    "\tforeign key(race) references race);\n",
    "\n",
    "create table level(\n",
    "\tlevel_id serial, \n",
    "\tlevel varchar(100),\n",
    "\tprimary key (level_id)\n",
    ");\n",
    "\n",
    "create table employee_level(\n",
    "\temployee_id int primary key,\n",
    "\tlevel_id int,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(level_id) references level);\n",
    "\n",
    "create table title(\n",
    "\ttitle_id serial primary key,\n",
    "\ttitle varchar(100) NOT NULL);\n",
    "    \n",
    "create table employee_title(\n",
    "\temployee_id int primary key,\n",
    "\ttitle_id int NOT NULL,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(title_id) references title);\n",
    "    \n",
    "create table other(\n",
    "\temployee_id int primary key,\n",
    "\tother_details varchar(1000),\n",
    "\tforeign key(employee_id) references employee);\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract, Transform and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee database table - since the employee records are unique without duplication, we can add\n",
    "# a column with incrementing integer numbers for the primary key of employee id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'employee_id', range(1, 1 + len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df=df[['employee_id','basesalary','bonus','stockgrantvalue','timestamp','totalyearlycompensation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df=employee_df.rename(columns={'basesalary':'base_salary','stockgrantvalue':'stock_value','bonus':'bonus_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.to_sql(name='employee', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading company database table - in the original csv data since there are repeating companies, we need to extract\n",
    "# the unique company names, add a column of incrementing integer numbers and then map these numbers back \n",
    "# to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_company_df = pd.DataFrame(df.company.unique(), columns=['company'])\n",
    "temp_company_df['company']=temp_company_df['company'].fillna(\"Unknown\")\n",
    "temp_company_df.insert(0, 'company_id', range(1, 1 + len(temp_company_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_company_df.to_sql(name='company', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a new column to the main dataframe, for the primary key which is company_id \n",
    "# this involves using temp_company_df to create a list mapping company_id using for loops\n",
    "# and then inserting this list to the main dataframe as a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company']=df['company'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_id_list = [temp_company_df.company_id[temp_company_df.company == i].values[0] for i in df.company]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(4, 'company_id', company_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading location database table - same as the company name attribute, since location has repetitive records\n",
    "# in the main dataframe, we need to first extract the unique location information to database, and then use\n",
    "# for-loop to add a column of incrementing integer numbers for each location_id to create a list, which is\n",
    "# used to map these numbers back to the main dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df['location'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.columns=['location_city','location_state','location_add1','location_add2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df_cs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_state'] = df_cs['location_state'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_add1'] = df_cs['location_add1'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_add2'] = df_cs['location_add2'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.insert(0, 'location_id', range(1, 1 + len(df_cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.to_sql(name='location', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df_cs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.columns=['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=pd.DataFrame(df_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.insert(0, 'location_id', range(1, 1 + len(df_cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_cs, left_on=['location'], right_on = ['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['employee_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_company table to the database, but since we have already created employee_id and company_id,\n",
    "# we don't need to add additional columns to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_company_df=df[['employee_id','company_id','location_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_company_df.to_sql(name='employee_company', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading specialization table to the database - since some tag attributes are duplicated, as what we did earlier,\n",
    "# we need to first extract the unique tag information to database, add a column of incrementing integer numbers\n",
    "# for each unique tag_id to create a list, which is then used to map these numbers back to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization_df = pd.DataFrame(df.tag.unique(), columns=['tag'])\n",
    "specialization_df['tag']=specialization_df['tag'].fillna(\"Unknown\")\n",
    "specialization_df.insert(0, 'tag_id', range(1, 1 + len(specialization_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization_df.to_sql(name='specialization', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping specialization or tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag']=df['tag'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_list = [specialization_df.tag_id[specialization_df.tag == i].values[0] for i in df.tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, 'tag_id', tag_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_specialization table to database, but since we have already created employee_id and tag_id in\n",
    "# the main dataframe, we just need to extract the necessary attributes, which are employee_id and tag_id, in\n",
    "# creating and loading the table to database without making changes to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_specialization_df=df[['employee_id','tag_id']]\n",
    "employee_specialization_df.to_sql(name='employee_specialization', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading education table to the database by extracting unique education level information, and then adding \n",
    "# education_id as the primary key to create a list, which is then used to map the numbers back to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df = pd.DataFrame(df.Education.unique(), columns=['Education'])\n",
    "education_df['Education']=education_df['Education'].fillna(\"Unknown\")\n",
    "education_df.insert(0, 'education_id', range(1, 1 + len(education_df)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df=education_df.rename(columns={'Education':'education'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df.to_sql(name='education', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping education_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Education']=df['Education'].fillna(\"Unknown\")\n",
    "education_id_list = [education_df.education_id[education_df.education == i].values[0] for i in df.Education]\n",
    "df.insert(1, 'education_id', education_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_qualification table to database with existing employee_id and education_id that were previously\n",
    "# created, without having to add addtional columns to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_qualification_df=df[['employee_id','education_id','yearsofexperience','yearsatcompany']]\n",
    "employee_qualification_df=employee_qualification_df.rename(columns={'yearsofexperience':'years_experience','yearsatcompany':'years_at_company'})\n",
    "employee_qualification_df.to_sql(name='employee_qualification', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loaidng gender table to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].replace(['Title: Senior Software Engineer'],'Unknown')\n",
    "df['gender']=df['gender'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.DataFrame(df.gender.unique(), columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df.to_sql(name='gender', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading race table to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Race']=df['Race'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = pd.DataFrame(df.Race.unique(), columns=['Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df=race_df.rename(columns={'Race':'race'})\n",
    "race_df.to_sql(name='race', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_demographics table to the database "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_demographics=df[['employee_id','gender','Race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_demographics=employee_demographics.rename(columns={'Race':'race'})\n",
    "employee_demographics.to_sql(name='employee_demographics', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading level table to the databse by extracting unique job level information from the level attribute\n",
    "# add a column of incrementing integer numbers to represent the primary key, level_id\n",
    "# create a list based on the unique level_id and then map the numbers back to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df = pd.DataFrame(df.level.unique(), columns=['level'])\n",
    "level_df['level']=level_df['level'].fillna(\"Unknown\")\n",
    "level_df.insert(0, 'level_id', range(1, 1 + len(level_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df.to_sql(name='level', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping level_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level']=df['level'].fillna(\"Unknown\")\n",
    "level_id_list = [level_df.level_id[level_df.level == i].values[0] for i in df.level]\n",
    "df.insert(1, 'level_id', level_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_level table to database using employee_id and level_id that was just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_level=df[['employee_id','level_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_level.to_sql(name='employee_level', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading title table to the databse by extracting unique job title information from the title attribute\n",
    "# add a column of incrementing integer numbers to represent the primary key, title_id\n",
    "# create a list based on the unique title_id and then map the numbers back to the main dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(df.title.unique(), columns=['title'])\n",
    "title_df['title']=title_df['title'].fillna(\"Unknown\")\n",
    "title_df.insert(0, 'title_id', range(1, 1 + len(title_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.to_sql(name='title', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping title_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title']=df['title'].fillna(\"Unknown\")\n",
    "title_id_list = [title_df.title_id[title_df.title == i].values[0] for i in df.title]\n",
    "df.insert(1, 'title_id', title_id_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading employee_title table to databse with employee_id and title_id that was just created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_title=df[['employee_id','title_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_title.to_sql(name='employee_title', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading other table to databse using extracted information from the \"otheretails\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "other=df[['employee_id','otherdetails']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "other=other.rename(columns={'otherdetails':'other_details'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "other.to_sql(name='other', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "ProgrammingError",
     "evalue": "(psycopg2.errors.DuplicateObject) role \"mytest\" already exists\n\n[SQL: \n\nCREATE USER mytest WITH\n\tLOGIN\n\tSUPERUSER\n\tCREATEDB\n\tCREATEROLE\n\tINHERIT\n\tNOREPLICATION\n\tCONNECTION LIMIT -1\n\tVALID UNTIL '2025-04-03T11:50:38+05:30' \n\tPASSWORD '123456';\n\n]\n(Background on this error at: http://sqlalche.me/e/13/f405)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDuplicateObject\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDuplicateObject\u001b[0m: role \"mytest\" already exists\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mProgrammingError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-b3367483b4c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m# Execute the statement and get the results\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mconnection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstmt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1004\u001b[0m         \"\"\"\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1008\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[1;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[0;32m   1173\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1174\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_distill_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1175\u001b[1;33m         ret = self._execute_context(\n\u001b[0m\u001b[0;32m   1176\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1177\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1316\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1317\u001b[1;33m             self._handle_dbapi_exception(\n\u001b[0m\u001b[0;32m   1318\u001b[0m                 \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   1509\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1510\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1511\u001b[1;33m                 util.raise_(\n\u001b[0m\u001b[0;32m   1512\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\util\\compat.py\u001b[0m in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    176\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 178\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    179\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m             \u001b[1;31m# credit to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[0;32m   1275\u001b[0m                             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1276\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1277\u001b[1;33m                     self.dialect.do_execute(\n\u001b[0m\u001b[0;32m   1278\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m                     )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sqlalchemy\\engine\\default.py\u001b[0m in \u001b[0;36mdo_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mProgrammingError\u001b[0m: (psycopg2.errors.DuplicateObject) role \"mytest\" already exists\n\n[SQL: \n\nCREATE USER mytest WITH\n\tLOGIN\n\tSUPERUSER\n\tCREATEDB\n\tCREATEROLE\n\tINHERIT\n\tNOREPLICATION\n\tCONNECTION LIMIT -1\n\tVALID UNTIL '2025-04-03T11:50:38+05:30' \n\tPASSWORD '123456';\n\n]\n(Background on this error at: http://sqlalche.me/e/13/f405)"
     ]
    }
   ],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "CREATE USER mytest WITH\n",
    "\tLOGIN\n",
    "\tSUPERUSER\n",
    "\tCREATEDB\n",
    "\tCREATEROLE\n",
    "\tINHERIT\n",
    "\tNOREPLICATION\n",
    "\tCONNECTION LIMIT -1\n",
    "\tVALID UNTIL '2025-04-03T11:50:38+05:30' \n",
    "\tPASSWORD '123456';\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "connection.execute(stmt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spot Checks & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is our analysis plan, which aims to first look at average salary information by different variables,\n",
    "# such as job title in particular, which is of greatest interest of our clients.\n",
    "# We then plan on taking a deep dive into one specific job title to see how salary varies by other variables \n",
    "# such as company, location, education, experience, etc., to provide a 360 view of salary information for our\n",
    "# clients depending on a specific job title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Average salary by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,company from employee,employee_company,company\n",
    "where employee.employee_id = employee_company.employee_id and company.company_id = employee_company.company_id\n",
    "group by company order by Avg_salary DESC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Average salary by job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,title from employee,employee_title,title\n",
    "where employee.employee_id = employee_title.employee_id and title.title_id = employee_title.title_id\n",
    "group by title order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results1 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results1[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df1 = pd.DataFrame(results1, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Average salary by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,location_city from employee,employee_company,location\n",
    "where employee.employee_id = employee_company.employee_id and location.location_id = employee_company.location_id\n",
    "group by location_city order by Avg_salary DESC limit 20\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results2 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results2[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df2 = pd.DataFrame(results2, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Average salary by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,location_state from employee,employee_company,location\n",
    "where employee.employee_id = employee_company.employee_id and location.location_id = employee_company.location_id\n",
    "group by location_state order by Avg_salary DESC limit 20\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results3 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results3[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df3 = pd.DataFrame(results3, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Level with the highest salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select max(totalyearlycompensation)as max_salary,company,level from employee,employee_level,level,company,employee_company\n",
    "where employee.employee_id = employee_level.employee_id and level.level_id = employee_level.level_id and\n",
    "employee.employee_id=employee_company.employee_id and company.company_id = employee_company.company_id\n",
    "group by level,company order by max_salary DESC \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results4 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results4[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df4 = pd.DataFrame(results4, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the following analyses we will focus on exploring data scientist salary by different variables\n",
    "#6 Data Scientist salary by the company and average working experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,avg(years_experience)as Avg_exp,company from \n",
    "employee,employee_company,company,employee_title,title,employee_qualification\n",
    "where employee.employee_id = employee_company.employee_id and company.company_id = employee_company.company_id \n",
    "and employee.employee_id = employee_qualification.employee_id\n",
    "and title.title_id = employee_title.title_id and employee.employee_id=employee_title.employee_id and title='Data Scientist'  \n",
    "group by company order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results5 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results5[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df5 = pd.DataFrame(results5, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Data scientist salary by working experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,years_experience from employee,employee_title,title,employee_qualification\n",
    "where employee.employee_id = employee_qualification.employee_id and employee.employee_id=employee_title.employee_id\n",
    "and title.title_id = employee_title.title_id and title='Data Scientist' \n",
    "group by years_experience order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results6 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results6[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df6 = pd.DataFrame(results6, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 data scientist salary by tag or specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,tag from employee,employee_title,title,employee_specialization,specialization\n",
    "where employee.employee_id = employee_specialization.employee_id and employee_specialization.tag_id=specialization.tag_id\n",
    "and title.title_id = employee_title.title_id and employee.employee_id=employee_title.employee_id and title='Data Scientist'  \n",
    "group by tag order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results7 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results7[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df7 = pd.DataFrame(results7, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Data Scientist salary Man VS women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,gender from employee,employee_title,title,employee_demographics\n",
    "where title.title_id = employee_title.title_id and employee.employee_id=employee_title.employee_id and title='Data Scientist' \n",
    "and employee_demographics.employee_id=employee.employee_id\n",
    "group by gender order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results8 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results8[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df8 = pd.DataFrame(results8, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#10 Data Scientist salary race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,race from employee,employee_title,title,employee_demographics\n",
    "where title.title_id = employee_title.title_id and employee.employee_id=employee_title.employee_id and title='Data Scientist' \n",
    "and employee_demographics.employee_id=employee.employee_id\n",
    "group by race order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results9 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results9[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df9 = pd.DataFrame(results9, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
