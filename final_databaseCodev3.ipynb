{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database System Development Plan\n",
    "##### GROUP 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is our database product offered to recruiting company with real company data and mock employee data. We provide insights with analytical techniques after the creation of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading CSV data into a new dataframe\n",
    "\n",
    "df = pd.read_csv('Levels_Fyi_Salary_Data.csv', low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the connection string to a variable, conn_url\n",
    "conn_url = 'postgresql://postgres:123@localhost/final5'\n",
    "\n",
    "# Create an engine that connects to PostgreSQL server\n",
    "engine = create_engine(conn_url)\n",
    "\n",
    "# Establish a connection\n",
    "connection = engine.connect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creation of Database Tables Based on Normalization Plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are now ready to create database tables based on the normalization plan that were developed earlier\n",
    "\n",
    "# Pass the SQL statements that create all tables\n",
    "stmt = \"\"\"\n",
    "create table employee(\n",
    "\temployee_id serial,\n",
    "\tbase_salary numeric(10,2),\n",
    "\tbonus_amount numeric(10,2),\n",
    "\tstock_value numeric(10,2),\n",
    "    totalyearlycompensation numeric(10,2),\n",
    "\ttimestamp timestamp NOT NULL,\n",
    "\tprimary key (employee_id)\n",
    ");\n",
    "\n",
    "create table contact(\n",
    "    employee_id serial,\n",
    "    first_name varchar(50),\n",
    "    last_name varchar(50),\n",
    "    primary key (employee_id),\n",
    "    foreign key(employee_id) references employee\n",
    ");\n",
    "\n",
    "create table phone_number(\n",
    "    employee_id serial,\n",
    "    phone_number varchar(50),\n",
    "    phone_type varchar(50),\n",
    "    primary key (employee_id,phone_number),\n",
    "    foreign key(employee_id) references employee\n",
    ");\n",
    "\n",
    "create table email(\n",
    "    employee_id serial,\n",
    "    email varchar(50),\n",
    "    email_type varchar(50),\n",
    "    primary key (employee_id,email),\n",
    "    foreign key(employee_id) references employee\n",
    ");\n",
    "\n",
    "create table address(\n",
    "    employee_id serial,\n",
    "    street_address varchar(50),\n",
    "    city varchar(30),\n",
    "    state varchar(30),\n",
    "    address_type varchar(30),\n",
    "    primary key (employee_id,street_address),\n",
    "    foreign key(employee_id) references employee\n",
    ");\n",
    "\n",
    "create table company(\n",
    "\tcompany_id serial,\n",
    "\tcompany varchar(100) NOT NULL,\n",
    "\tprimary key (company_id)\n",
    ");\n",
    "\n",
    "create table location(\n",
    "\tlocation_id serial,\n",
    "\tlocation_city varchar(100),\n",
    "\tlocation_state varchar(100),\n",
    "    location_add1 varchar(100),\n",
    "    location_add2 varchar(100),\n",
    "\tprimary key (location_id)\n",
    ");\n",
    "\n",
    "create table employee_company(\n",
    "\temployee_id int,\n",
    "\tcompany_id int,\n",
    "\tlocation_id int,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(company_id) references company,\n",
    "\tforeign key(location_id) references location,\n",
    "\tprimary key (employee_id, company_id, location_id)\n",
    ");\n",
    "\n",
    "create table specialization(\n",
    "\ttag_id serial,\n",
    "\ttag varchar(200),\n",
    "\tprimary key (tag_id)\n",
    ");\n",
    "\n",
    "create table employee_specialization(\n",
    "\temployee_id int,\n",
    "\ttag_id int,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(tag_id) references specialization,\n",
    "\tprimary key(employee_id)\n",
    ");\n",
    "\n",
    "create table ref_education(\n",
    "\teducation varchar(50),\n",
    "\tprimary key(education)\n",
    ");\n",
    "\n",
    "create table employee_qualification(\n",
    "\temployee_id int,\n",
    "\teducation varchar(50),\n",
    "\tyears_at_company int ,\n",
    "\tyears_experience int ,\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(education) references ref_education,\n",
    "\tprimary key(employee_id)\n",
    ");\n",
    "\n",
    "create table gender(\n",
    "\tgender varchar(10),\n",
    "\tcheck (gender \n",
    "\t\t\tin ('Male','Female', 'Other','Unknown')),\n",
    "\tprimary key(gender)\n",
    ");\n",
    "    \n",
    "create table race(\n",
    "\trace varchar(50) primary key\n",
    ");\n",
    "    \n",
    "create table employee_demographics(\n",
    "\temployee_id int primary key,\n",
    "\tgender varchar(10),\n",
    "\trace varchar(50),\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(gender) references gender,\n",
    "\tforeign key(race) references race\n",
    ");\n",
    "\n",
    "create table level(\n",
    "\tlevel_id serial, \n",
    "\tlevel varchar(100),\n",
    "\tprimary key (level_id)\n",
    ");\n",
    "\n",
    "create table ref_title(\n",
    "\ttitle varchar(50),\n",
    "\tprimary key(title)\n",
    ");\n",
    "\n",
    "create table employee_position(\n",
    "\temployee_id int primary key,\n",
    "\tlevel_id int,\n",
    "    title varchar(50),\n",
    "\tforeign key(employee_id) references employee,\n",
    "\tforeign key(level_id) references level,\n",
    "    foreign key(title) references ref_title\n",
    ");\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "connection.execute(stmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extract, Transform and Load**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee table \n",
    "##### *loading employee database table - since the employee records are unique without duplication, we can add a column with incrementing integer numbers for the primary key of employee id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(0, 'employee_id', range(1, 1 + len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df=df[['employee_id','basesalary','bonus','stockgrantvalue','timestamp','totalyearlycompensation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df=employee_df.rename(columns={'basesalary':'base_salary','stockgrantvalue':'stock_value','bonus':'bonus_amount'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_df.to_sql(name='employee', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add company table**\n",
    "##### *loading company database table - in the original csv data since there are repeating companies, we need to extract the unique company names, add a column of incrementing integer numbers and then map these numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_company_df = pd.DataFrame(df.company.unique(), columns=['company'])\n",
    "temp_company_df['company']=temp_company_df['company'].fillna(\"Unknown\")\n",
    "temp_company_df.insert(0, 'company_id', range(1, 1 + len(temp_company_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_company_df.to_sql(name='company', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### *adding a new column to the main dataframe, for the primary key which is company_id this involves using temp_company_df to create a list mapping company_id using for loops and then inserting this list to the main dataframe as a new column*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company']=df['company'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_id_list = [temp_company_df.company_id[temp_company_df.company == i].values[0] for i in df.company]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(4, 'company_id', company_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Add location table**\n",
    "##### *loading location database table - same as the company name attribute, since location has repetitive records in the main dataframe, we need to first extract the unique location information to database, and then use for-loop to add a column of incrementing integer numbers for each location_id to create a list, which is used to map these numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df['location'].str.split(',', expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.columns=['location_city','location_state','location_add1','location_add2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df_cs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_state'] = df_cs['location_state'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_add1'] = df_cs['location_add1'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs['location_add2'] = df_cs['location_add2'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.insert(0, 'location_id', range(1, 1 + len(df_cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.to_sql(name='location', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping location_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=df_cs.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.columns=['location']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs=pd.DataFrame(df_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cs.insert(0, 'location_id', range(1, 1 + len(df_cs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, df_cs, left_on=['location'], right_on = ['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.sort_values(by=['employee_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee_company table\n",
    "##### *loading employee_company table to the database, but since we have already created employee_id and company_id, we don't need to add additional columns to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_company_df=df[['employee_id','company_id','location_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_company_df.to_sql(name='employee_company', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Contact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'First Name':'first_name','Last Name':'last_name'})\n",
    "contact_df = df[['employee_id', 'first_name', 'last_name']]\n",
    "contact_df=contact_df.dropna(subset=['first_name', 'last_name'])\n",
    "contact_df.to_sql(name='contact', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Phone Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'Work Phone':'work_phone','Home Phone':'home_phone','Work Email':'work_email','Personal Email':'personal_email'})\n",
    "work_phone_df=df[['employee_id','work_phone']]\n",
    "work_phone_df=work_phone_df.rename(columns={'work_phone':'phone_number'})\n",
    "work_phone_df=work_phone_df.dropna(subset=['phone_number'])\n",
    "work_phone_df.insert(2, 'phone_type','work')\n",
    "work_phone_df.to_sql(name='phone_number', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_phone_df=df[['employee_id','home_phone']]\n",
    "home_phone_df=home_phone_df.rename(columns={'home_phone':'phone_number'})\n",
    "home_phone_df=home_phone_df.dropna(subset=['phone_number'])\n",
    "home_phone_df.insert(2, 'phone_type','home')\n",
    "home_phone_df.to_sql(name='phone_number', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Email Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "work_email_df=df[['employee_id','work_email']]\n",
    "work_email_df=work_email_df.rename(columns={'work_email':'email'})\n",
    "work_email_df=work_email_df.dropna(subset=['email'])\n",
    "work_email_df.insert(2, 'email_type','work')\n",
    "work_email_df.to_sql(name='email', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "personal_email_df=df[['employee_id','personal_email']]\n",
    "personal_email_df=personal_email_df.rename(columns={'personal_email':'email'})\n",
    "personal_email_df=personal_email_df.dropna(subset=['email'])\n",
    "personal_email_df.insert(2, 'email_type','home')\n",
    "personal_email_df.to_sql(name='email', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Address  Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.rename(columns={'work street address':'work_street_address','work city':'work_city','work state':'work_state',\n",
    "                      'home street address':'home_street_address','home city':'home_city','home state':'home_state'})\n",
    "work_address_df=df[['employee_id','work_street_address','work_city','work_state']]\n",
    "work_address_df=work_address_df.rename(columns={'work_street_address':'street_address','work_city':'city','work_state':'state'})\n",
    "work_address_df=work_address_df.dropna(subset=['street_address','city','state'])\n",
    "work_address_df.insert(4, 'address_type','work')\n",
    "work_address_df.to_sql(name='address', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_address_df=df[['employee_id','home_street_address','home_city','home_state']]\n",
    "home_address_df=home_address_df.rename(columns={'home_street_address':'street_address','home_city':'city','home_state':'state'})\n",
    "home_address_df=home_address_df.dropna(subset=['street_address','city','state'])\n",
    "home_address_df.insert(4, 'address_type','home')\n",
    "home_address_df.to_sql(name='address', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Specialization Table\n",
    "##### *loading specialization table to the database - since some tag attributes are duplicated, as what we did earlier, we need to first extract the unique tag information to database, add a column of incrementing integer numbers for each unique tag_id to create a list, which is then used to map these numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization_df = pd.DataFrame(df.tag.unique(), columns=['tag'])\n",
    "specialization_df['tag']=specialization_df['tag'].fillna(\"Unknown\")\n",
    "specialization_df.insert(0, 'tag_id', range(1, 1 + len(specialization_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "specialization_df.to_sql(name='specialization', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping specialization or tag_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tag']=df['tag'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_id_list = [specialization_df.tag_id[specialization_df.tag == i].values[0] for i in df.tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(1, 'tag_id', tag_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee_specialization table\n",
    "##### *loading employee_specialization table to database, but since we have already created employee_id and tag_id in the main dataframe, we just need to extract the necessary attributes, which are employee_id and tag_id, in creating and loading the table to database without making changes to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_specialization_df=df[['employee_id','tag_id']]\n",
    "employee_specialization_df.to_sql(name='employee_specialization', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ref_education table\n",
    "##### *loading education table to the database by extracting unique education level information, and then adding education_id as the primary key to create a list, which is then used to map the numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df = pd.DataFrame(df.Education.unique(), columns=['Education'])\n",
    "education_df['Education']=education_df['Education'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df=education_df.rename(columns={'Education':'education'})\n",
    "df=df.rename(columns={'Education':'education'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_df.to_sql(name='ref_education', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee_qualification table\n",
    "##### *loading education table to the database by extracting unique education level information, and then adding education_id as the primary key to create a list, which is then used to map the numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_qualification_df=df[['employee_id','education','yearsofexperience','yearsatcompany']]\n",
    "employee_qualification_df=employee_qualification_df.rename(columns={'yearsofexperience':'years_experience','yearsatcompany':'years_at_company'})\n",
    "employee_qualification_df.to_sql(name='employee_qualification', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add gender table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender']=df['gender'].replace(['Title: Senior Software Engineer'],'Unknown')\n",
    "df['gender']=df['gender'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df = pd.DataFrame(df.gender.unique(), columns=['gender'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_df.to_sql(name='gender', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add race table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Race']=df['Race'].fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df = pd.DataFrame(df.Race.unique(), columns=['Race'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_df=race_df.rename(columns={'Race':'race'})\n",
    "race_df.to_sql(name='race', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee_demographic table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_demographics=df[['employee_id','gender','Race']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_demographics=employee_demographics.rename(columns={'Race':'race'})\n",
    "employee_demographics.to_sql(name='employee_demographics', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add job_level table\n",
    "##### *loading level table to the databse by extracting unique job level information from the level attribute add a column of incrementing integer numbers to represent the primary key, level_id create a list based on the unique level_id and then map the numbers back to the main dataframe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df = pd.DataFrame(df.level.unique(), columns=['level'])\n",
    "level_df['level']=level_df['level'].fillna(\"Unknown\")\n",
    "level_df.insert(0, 'level_id', range(1, 1 + len(level_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_df.to_sql(name='level', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping level_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['level']=df['level'].fillna(\"Unknown\")\n",
    "level_id_list = [level_df.level_id[level_df.level == i].values[0] for i in df.level]\n",
    "df.insert(1, 'level_id', level_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add ref_title table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = pd.DataFrame(df.title.unique(), columns=['title'])\n",
    "title_df['title']=title_df['title'].fillna(\"Unknown\")\n",
    "title_df.to_sql(name='ref_title', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add employee_position table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_position=df[['employee_id','level_id', 'title']]\n",
    "employee_position.to_sql(name='employee_position', con=engine, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Users & Priveleges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "CREATE GROUP new_analyst_read_only;\n",
    "\n",
    "CREATE USER newanalyst1 WITH\n",
    "    IN GROUP analyst_read_only\n",
    "\tVALID UNTIL '2025-04-03T11:50:38+05:30' \n",
    "\tPASSWORD '123456';\n",
    "    \n",
    "GRANT SELECT ON \n",
    "    employee,contact,phone_number,email,address,company,location,employee_company,specialization,\n",
    "    employee_specialization,ref_education,employee_qualification,gender,race,employee_demographics,level,\n",
    "    ref_title,employee_position\n",
    "    TO ANALYST1;\n",
    "    \n",
    "CREATE USER newanalyst2 WITH \n",
    "    SUPERUSER\n",
    "    CREATEDB\n",
    "    VALID UNTIL '2025-04-03T11:50:38+05:30' \n",
    "\tPASSWORD '111';\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "connection.execute(stmt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytical Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After the ETL process when all tables have been loaded to SQL, data analysts will be using Python to interact with the pgAdmin database system for data analysis purposes. \n",
    "\n",
    "### We offer insights and analytical techniques below, first is exploring average salary information by different variables, the second component involves looking at how salary varies by variables of interest given a specific job title. These tasks will be accomplished based on the establishment of a number of views so that analysts can appraoch requests more efficiently. We then plan on taking a deep dive into one specific job title to see how salary varies by other variables such as company, location, education, experience, etc., to provide a 360 view of salary information for our clients depending on a specific job title."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #1 Average salary by company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,company from employee,employee_company,company\n",
    "where employee.employee_id = employee_company.employee_id and company.company_id = employee_company.company_id\n",
    "group by company order by Avg_salary DESC\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Function to get Average salary for company "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "\n",
    "stmt = \"\"\"\n",
    "create or replace function avg_salary_company(state varchar(100))\n",
    "    returns table (\n",
    "        company varchar(100),\n",
    "        avg_salary numeric(10,2)) as\n",
    "    $$\n",
    "        begin\n",
    "            return query\n",
    "            select distinct co.company, avg(em.totalyearlycompensation) as avg_salary\n",
    "            from employee em\n",
    "            join employee_company ec on ec.employee_id = em.employee_id\n",
    "            join company co on ec.company_id = co.company_id\n",
    "            group by co.company;\n",
    "        end\n",
    "    $$\n",
    "language plpgsql; \n",
    "\n",
    "select * from avg_salary_company('Amazon');\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df = pd.DataFrame(results, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #2 Average salary by job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,title from employee,employee_position\n",
    "where employee.employee_id = employee_position.employee_id\n",
    "group by title order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results1 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results1[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df1 = pd.DataFrame(results1, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Function to get Average salary for job title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "create or replace function avg_salary_title(state varchar(100))\n",
    "    returns table (\n",
    "        title varchar(100),\n",
    "        avg_salary numeric(10,2)) as\n",
    "    $$\n",
    "        begin\n",
    "            return query\n",
    "            select distinct ep.title, avg(em.totalyearlycompensation) as avg_salary\n",
    "            from employee em\n",
    "            join employee_position ep on em.employee_id = ep.employee_id\n",
    "            group by ep.title;\n",
    "        end\n",
    "    $$\n",
    "language plpgsql; \n",
    "\n",
    "select * from avg_salary_title('Product Manager');\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results1 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results1[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df1 = pd.DataFrame(results1, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #3 Average salary by city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,location_city from employee,employee_company,location\n",
    "where employee.employee_id = employee_company.employee_id and location.location_id = employee_company.location_id\n",
    "group by location_city order by Avg_salary DESC limit 20\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results2 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results2[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df2 = pd.DataFrame(results2, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Function to get Average salary for a state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "create or replace function avg_salary_state(state varchar(100))\n",
    "    returns table (\n",
    "        location_name varchar(100),\n",
    "        avg_salary numeric(10,2)) as\n",
    "    $$\n",
    "        begin\n",
    "            return query\n",
    "            select distinct lo.location_state, avg(em.totalyearlycompensation) as avg_salary\n",
    "            from location lo\n",
    "            join employee_company ec on lo.location_id = ec.location_id\n",
    "            join employee em on em.employee_id = ec.employee_id\n",
    "            group by lo.location_state;\n",
    "        end\n",
    "    $$\n",
    "language plpgsql; \n",
    "\n",
    "\n",
    "select * from avg_salary_state('CA');\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results2 = connection.execute(stmt).fetchall()\n",
    "\n",
    "\n",
    "# Extract column names\n",
    "column_names = results2[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df2 = pd.DataFrame(results2, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #4 Average salary by state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,location_state from employee,employee_company,location\n",
    "where employee.employee_id = employee_company.employee_id and location.location_id = employee_company.location_id\n",
    "group by location_state order by Avg_salary DESC limit 20\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results3 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results3[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df3 = pd.DataFrame(results3, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #5 Level with the highest salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select max(totalyearlycompensation)as max_salary,company,level from level,employee,employee_position,company,employee_company\n",
    "where employee.employee_id = employee_position.employee_id and employee.employee_id=employee_company.employee_id and company.company_id = employee_company.company_id\n",
    "and level.level_id = employee_position.level_id\n",
    "group by level,company order by max_salary DESC \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results4 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results4[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df4 = pd.DataFrame(results4, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #6 Average salary by degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary, education \n",
    "from employee join employee_qualification using (employee_id)\n",
    "group by education \n",
    "order by Avg_salary DESC;\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results4 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results4[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df4 = pd.DataFrame(results4, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the following analyses we will focus on exploring data scientist salary by different variables\n",
    "### #7 Data Scientist salary by the company and average working experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,avg(years_experience)as Avg_exp,company from \n",
    "employee,employee_company,company,employee_position,employee_qualification\n",
    "where employee.employee_id = employee_company.employee_id and company.company_id = employee_company.company_id \n",
    "and employee.employee_id = employee_qualification.employee_id\n",
    "and employee.employee_id=employee_position.employee_id \n",
    "and title='Data Scientist' \n",
    "group by company,title order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results5 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results5[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df5 = pd.DataFrame(results5, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #8 Data scientist salary by years experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,years_experience \n",
    "from employee,employee_position,employee_qualification\n",
    "where employee.employee_id = employee_qualification.employee_id and employee.employee_id=employee_position.employee_id\n",
    "and title='Data Scientist' \n",
    "group by years_experience order by years_experience\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results6 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results6[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df6 = pd.DataFrame(results6, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #9 Data scientist salary by tag or specialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,tag from employee,employee_position,employee_specialization,specialization\n",
    "where employee.employee_id = employee_specialization.employee_id and employee_specialization.tag_id=specialization.tag_id\n",
    "and employee.employee_id=employee_position.employee_id and title='Data Scientist'  \n",
    "group by tag order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results7 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results7[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df7 = pd.DataFrame(results7, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #10 Data Scientist salary by gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,gender from employee,employee_position,employee_demographics\n",
    "where employee.employee_id=employee_position.employee_id and title='Data Scientist' \n",
    "and employee_demographics.employee_id=employee.employee_id\n",
    "group by gender order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results8 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results8[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df8 = pd.DataFrame(results8, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### #11 Data Scientist salary race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass the SQL statement to filter data\n",
    "stmt = \"\"\"\n",
    "\n",
    "select avg(totalyearlycompensation)as Avg_salary,race from employee,employee_position,employee_demographics\n",
    "where employee.employee_id=employee_position.employee_id and title='Data Scientist' \n",
    "and employee_demographics.employee_id=employee.employee_id\n",
    "group by race order by Avg_salary DESC\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Execute the statement and get the results\n",
    "results9 = connection.execute(stmt).fetchall()\n",
    "\n",
    "# Extract column names\n",
    "column_names = results9[0].keys()\n",
    "\n",
    "# Store results in a new dataframe\n",
    "temp_df9 = pd.DataFrame(results9, columns=column_names)\n",
    "\n",
    "# Show results\n",
    "temp_df9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
